% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/torch_modules.R
\name{wand_mlp_module}
\alias{wand_mlp_module}
\title{A multilayer perceptron \code{torch::nn_module} module}
\usage{
wand_mlp_module(n_features, hidden_units)
}
\arguments{
\item{n_features}{An integer giving the number of input features.}

\item{hidden_units}{An integer vector giving the size of each layer. The final element gives the
number of features returned by the module.}
}
\value{
A multilayer perceptron \code{torch::nn_module} module
}
\description{
A multilayer perceptron \code{torch::nn_module} module
}
\details{
This module creates a very simple multilayer perceptron (mlp). The mlp uses the \code{torch::nn_selu}
activation function, no dropout, and no batchnormalization. Note that the activation function is
applied to the returned features.
}
