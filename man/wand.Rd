% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/wand-fit.R
\name{wand}
\alias{wand}
\alias{wand.default}
\alias{wand.data.frame}
\alias{wand.matrix}
\alias{wand.formula}
\alias{wand.recipe}
\title{Fit a \code{wand} model}
\usage{
wand(x, ...)

\method{wand}{default}(x, ...)

\method{wand}{data.frame}(
  x,
  y,
  smooth_specs = list(),
  batch_size = 32,
  validation_prop = 0.1,
  epochs = 10,
  learn_rate = 3e-04,
  stop_iter = 5,
  verbose = F,
  ...
)

\method{wand}{matrix}(
  x,
  y,
  smooth_specs = list(),
  batch_size = 32,
  validation_prop = 0.1,
  epochs = 10,
  learn_rate = 3e-04,
  stop_iter = 5,
  verbose = F,
  ...
)

\method{wand}{formula}(
  formula,
  data,
  batch_size = 32,
  validation_prop = 0.1,
  epochs = 10,
  learn_rate = 3e-04,
  stop_iter = 5,
  verbose = F,
  ...
)

\method{wand}{recipe}(
  x,
  data,
  smooth_specs = list(),
  batch_size = 32,
  validation_prop = 0.1,
  epochs = 10,
  learn_rate = 3e-04,
  stop_iter = 5,
  verbose = F,
  ...
)
}
\arguments{
\item{x}{Depending on the context:
\itemize{
\item A \strong{data frame} of predictors.
\item A \strong{matrix} of predictors.
\item A \strong{recipe} specifying a set of preprocessing steps
created from \code{\link[recipes:recipe]{recipes::recipe()}}.
}}

\item{...}{Not currently used, but required for extensibility.}

\item{y}{When \code{x} is a \strong{data frame} or \strong{matrix}, \code{y} is the outcome
specified as:
\itemize{
\item A \strong{data frame} with 1 numeric column.
\item A \strong{matrix} with 1 numeric column.
\item A numeric \strong{vector}.
}}

\item{smooth_specs}{A named list of smooth specifications. A specification is simply the output
oaf \code{s_} functions like \code{s_mlp}. If the list is not named, or if a \strong{formula} is used, the
smooths will be named sequentially. When using a \strong{formula} the smooths are specified directly
as part of the formula.}

\item{batch_size}{An integer giving the number of training samples included in each minibatch.}

\item{validation_prop}{The proportion of training samples assigned to the validation set.}

\item{epochs}{An integer giving the number of training epochs.}

\item{learn_rate}{The initial learning rate used by the optimizer.}

\item{stop_iter}{A non-negative integer giving the number of epochs with no improvement in loss
before training is stopped. If \code{validation_prop > 0} then validation loss is used, otherwise
loss is evaluated using the whole training set. Set this parameter to \code{Inf} to prevent any
early stopping.}

\item{verbose}{A logical. When \code{TRUE} the loss, and validation loss if relevant, will be printed
out for each epoch, along with other training messages.}

\item{formula}{A formula specifying the outcome terms on the left-hand side,
and the predictor terms on the right-hand side.}

\item{data}{When a \strong{recipe} or \strong{formula} is used, \code{data} is specified as:
\itemize{
\item A \strong{data frame} containing both the predictors and the outcome.
}}
}
\value{
A \code{wand} object.
}
\description{
\code{wand()} fits a wide and deep neural network, where the wide part of the network treats features
as linear, and the deep parts of the network uses neural network submodules to smooth features.
}
\details{
TODO :)
}
\examples{
\donttest{
if (torch::torch_is_installed()) {
  predictors <- mtcars[, -1]
  outcome <- mtcars[, 1]

  # XY interface
  mod <- wand(predictors, outcome, smooth_specs = list(hp = s_mlp(hp)))

  # Formula interface
  mod2 <- wand(mpg ~ s_mlp(hp) + disp, mtcars)

  # Recipes interface
  library(recipes)
  rec <- recipe(mpg ~ ., mtcars)
  rec <- step_log(rec, disp)
  mod3 <- wand(rec, mtcars, smooth_specs = list(hp = s_mlp(hp), disp = s_mlp(disp)))
}
}
}
